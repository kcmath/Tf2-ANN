{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN - BreastCancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5ugpt2JhQ9SxiiiaH7gfC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5aXE4e_g98F",
        "colab_type": "code",
        "outputId": "3ff8e10d-bd0c-4793-bc0d-80d3dbe80dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install TensorFlow\n",
        "!pip install tensorflow-gpu\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 73.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (42.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5f/a1a02695b96d0e09c38abf7d1576b137979cea3d060d60891622cf61276d/google_auth-1.10.1-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed google-auth-1.10.1 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n",
            "/device:GPU:0\n",
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQZfS_I9jkJa",
        "colab_type": "code",
        "outputId": "a5912d32-2470-468e-aeaf-e229b69ac2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Load in the data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "# load the data\n",
        "data = load_breast_cancer()\n",
        "# check the type of 'data'\n",
        "type(data)\n",
        "# note: it is a Bunch object\n",
        "# this basically acts like a dictionary where you can treat the keys like attributes\n",
        "data.keys()\n",
        "# 'data' (the attribute) means the input data\n",
        "data.data.shape\n",
        "# it has 569 samples, 30 features\n",
        "# 'targets'\n",
        "data.target\n",
        "# note how the targets are just 0s and 1s\n",
        "# normally, when you have K targets, they are labeled 0..K-1\n",
        "# their meaning is not lost\n",
        "data.target_names\n",
        "# there are also 569 corresponding targets\n",
        "data.target.shape\n",
        "# you can also determine the meaning of each feature\n",
        "data.feature_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tweurqzSj5Oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normally we would put all of our imports at the top\n",
        "# but this lets us tell a story\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# split the data into train and test sets\n",
        "# this lets us simulate how our model will perform in the future\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
        "N, D = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQgYZNqRm9nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data\n",
        "# you'll learn why scaling is needed in a later course\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiraAQkCj6uY",
        "colab_type": "code",
        "outputId": "ab03c37d-cc64-4478-d934-6bb3321e26dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Now all the fun Tensorflow stuff\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=(D,)),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Alternatively, you can do:\n",
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)\n",
        "\n",
        "\n",
        "# Evaluate the model - evaluate() returns loss and accuracy\n",
        "print(\"Train score:\", model.evaluate(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/100\n",
            "381/381 [==============================] - 2s 6ms/sample - loss: 0.6131 - accuracy: 0.7087 - val_loss: 0.5752 - val_accuracy: 0.7021\n",
            "Epoch 2/100\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.5636 - accuracy: 0.7585 - val_loss: 0.5263 - val_accuracy: 0.7447\n",
            "Epoch 3/100\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.5191 - accuracy: 0.7953 - val_loss: 0.4849 - val_accuracy: 0.7872\n",
            "Epoch 4/100\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.4825 - accuracy: 0.8110 - val_loss: 0.4484 - val_accuracy: 0.8138\n",
            "Epoch 5/100\n",
            "381/381 [==============================] - 0s 167us/sample - loss: 0.4503 - accuracy: 0.8294 - val_loss: 0.4170 - val_accuracy: 0.8245\n",
            "Epoch 6/100\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.4212 - accuracy: 0.8399 - val_loss: 0.3903 - val_accuracy: 0.8404\n",
            "Epoch 7/100\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.3965 - accuracy: 0.8478 - val_loss: 0.3668 - val_accuracy: 0.8511\n",
            "Epoch 8/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.3743 - accuracy: 0.8556 - val_loss: 0.3462 - val_accuracy: 0.8617\n",
            "Epoch 9/100\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.3545 - accuracy: 0.8661 - val_loss: 0.3278 - val_accuracy: 0.8617\n",
            "Epoch 10/100\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.3367 - accuracy: 0.8714 - val_loss: 0.3111 - val_accuracy: 0.8777\n",
            "Epoch 11/100\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.3208 - accuracy: 0.8793 - val_loss: 0.2961 - val_accuracy: 0.8883\n",
            "Epoch 12/100\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.3060 - accuracy: 0.8950 - val_loss: 0.2828 - val_accuracy: 0.8936\n",
            "Epoch 13/100\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.2927 - accuracy: 0.9055 - val_loss: 0.2708 - val_accuracy: 0.9043\n",
            "Epoch 14/100\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.2807 - accuracy: 0.9081 - val_loss: 0.2597 - val_accuracy: 0.9043\n",
            "Epoch 15/100\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.2699 - accuracy: 0.9134 - val_loss: 0.2495 - val_accuracy: 0.9096\n",
            "Epoch 16/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.2594 - accuracy: 0.9134 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
            "Epoch 17/100\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.2500 - accuracy: 0.9213 - val_loss: 0.2322 - val_accuracy: 0.9202\n",
            "Epoch 18/100\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.2416 - accuracy: 0.9239 - val_loss: 0.2244 - val_accuracy: 0.9309\n",
            "Epoch 19/100\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.2336 - accuracy: 0.9265 - val_loss: 0.2172 - val_accuracy: 0.9362\n",
            "Epoch 20/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.2259 - accuracy: 0.9291 - val_loss: 0.2107 - val_accuracy: 0.9362\n",
            "Epoch 21/100\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.2193 - accuracy: 0.9318 - val_loss: 0.2047 - val_accuracy: 0.9415\n",
            "Epoch 22/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.2130 - accuracy: 0.9370 - val_loss: 0.1990 - val_accuracy: 0.9415\n",
            "Epoch 23/100\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.2069 - accuracy: 0.9370 - val_loss: 0.1939 - val_accuracy: 0.9415\n",
            "Epoch 24/100\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.2013 - accuracy: 0.9423 - val_loss: 0.1890 - val_accuracy: 0.9468\n",
            "Epoch 25/100\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1964 - accuracy: 0.9449 - val_loss: 0.1842 - val_accuracy: 0.9468\n",
            "Epoch 26/100\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.1914 - accuracy: 0.9449 - val_loss: 0.1799 - val_accuracy: 0.9468\n",
            "Epoch 27/100\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1869 - accuracy: 0.9475 - val_loss: 0.1759 - val_accuracy: 0.9468\n",
            "Epoch 28/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1826 - accuracy: 0.9475 - val_loss: 0.1722 - val_accuracy: 0.9468\n",
            "Epoch 29/100\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.1785 - accuracy: 0.9501 - val_loss: 0.1686 - val_accuracy: 0.9468\n",
            "Epoch 30/100\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1748 - accuracy: 0.9528 - val_loss: 0.1653 - val_accuracy: 0.9468\n",
            "Epoch 31/100\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1715 - accuracy: 0.9554 - val_loss: 0.1622 - val_accuracy: 0.9468\n",
            "Epoch 32/100\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.1679 - accuracy: 0.9554 - val_loss: 0.1591 - val_accuracy: 0.9468\n",
            "Epoch 33/100\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.1647 - accuracy: 0.9554 - val_loss: 0.1563 - val_accuracy: 0.9468\n",
            "Epoch 34/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1618 - accuracy: 0.9606 - val_loss: 0.1536 - val_accuracy: 0.9468\n",
            "Epoch 35/100\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1588 - accuracy: 0.9606 - val_loss: 0.1511 - val_accuracy: 0.9521\n",
            "Epoch 36/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1562 - accuracy: 0.9606 - val_loss: 0.1488 - val_accuracy: 0.9521\n",
            "Epoch 37/100\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.1537 - accuracy: 0.9633 - val_loss: 0.1463 - val_accuracy: 0.9521\n",
            "Epoch 38/100\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1511 - accuracy: 0.9659 - val_loss: 0.1441 - val_accuracy: 0.9521\n",
            "Epoch 39/100\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1488 - accuracy: 0.9659 - val_loss: 0.1421 - val_accuracy: 0.9574\n",
            "Epoch 40/100\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1465 - accuracy: 0.9659 - val_loss: 0.1401 - val_accuracy: 0.9574\n",
            "Epoch 41/100\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.1444 - accuracy: 0.9659 - val_loss: 0.1383 - val_accuracy: 0.9574\n",
            "Epoch 42/100\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1424 - accuracy: 0.9659 - val_loss: 0.1364 - val_accuracy: 0.9574\n",
            "Epoch 43/100\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1405 - accuracy: 0.9685 - val_loss: 0.1347 - val_accuracy: 0.9574\n",
            "Epoch 44/100\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1387 - accuracy: 0.9711 - val_loss: 0.1329 - val_accuracy: 0.9574\n",
            "Epoch 45/100\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.1368 - accuracy: 0.9711 - val_loss: 0.1313 - val_accuracy: 0.9574\n",
            "Epoch 46/100\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.1351 - accuracy: 0.9711 - val_loss: 0.1298 - val_accuracy: 0.9628\n",
            "Epoch 47/100\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1334 - accuracy: 0.9711 - val_loss: 0.1283 - val_accuracy: 0.9628\n",
            "Epoch 48/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1320 - accuracy: 0.9711 - val_loss: 0.1270 - val_accuracy: 0.9628\n",
            "Epoch 49/100\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1304 - accuracy: 0.9711 - val_loss: 0.1255 - val_accuracy: 0.9628\n",
            "Epoch 50/100\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1289 - accuracy: 0.9711 - val_loss: 0.1242 - val_accuracy: 0.9628\n",
            "Epoch 51/100\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1275 - accuracy: 0.9711 - val_loss: 0.1228 - val_accuracy: 0.9628\n",
            "Epoch 52/100\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1261 - accuracy: 0.9711 - val_loss: 0.1216 - val_accuracy: 0.9628\n",
            "Epoch 53/100\n",
            "381/381 [==============================] - 0s 158us/sample - loss: 0.1248 - accuracy: 0.9711 - val_loss: 0.1203 - val_accuracy: 0.9628\n",
            "Epoch 54/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1235 - accuracy: 0.9711 - val_loss: 0.1192 - val_accuracy: 0.9628\n",
            "Epoch 55/100\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1223 - accuracy: 0.9711 - val_loss: 0.1181 - val_accuracy: 0.9628\n",
            "Epoch 56/100\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1211 - accuracy: 0.9711 - val_loss: 0.1170 - val_accuracy: 0.9628\n",
            "Epoch 57/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1200 - accuracy: 0.9738 - val_loss: 0.1159 - val_accuracy: 0.9628\n",
            "Epoch 58/100\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1189 - accuracy: 0.9738 - val_loss: 0.1150 - val_accuracy: 0.9628\n",
            "Epoch 59/100\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.1178 - accuracy: 0.9738 - val_loss: 0.1140 - val_accuracy: 0.9628\n",
            "Epoch 60/100\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.1168 - accuracy: 0.9738 - val_loss: 0.1128 - val_accuracy: 0.9628\n",
            "Epoch 61/100\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1158 - accuracy: 0.9738 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
            "Epoch 62/100\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1148 - accuracy: 0.9738 - val_loss: 0.1110 - val_accuracy: 0.9628\n",
            "Epoch 63/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1138 - accuracy: 0.9738 - val_loss: 0.1101 - val_accuracy: 0.9628\n",
            "Epoch 64/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1130 - accuracy: 0.9738 - val_loss: 0.1093 - val_accuracy: 0.9628\n",
            "Epoch 65/100\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1121 - accuracy: 0.9738 - val_loss: 0.1084 - val_accuracy: 0.9628\n",
            "Epoch 66/100\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.1112 - accuracy: 0.9738 - val_loss: 0.1076 - val_accuracy: 0.9628\n",
            "Epoch 67/100\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.1104 - accuracy: 0.9738 - val_loss: 0.1069 - val_accuracy: 0.9628\n",
            "Epoch 68/100\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.1096 - accuracy: 0.9738 - val_loss: 0.1062 - val_accuracy: 0.9628\n",
            "Epoch 69/100\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1088 - accuracy: 0.9738 - val_loss: 0.1053 - val_accuracy: 0.9628\n",
            "Epoch 70/100\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.1079 - accuracy: 0.9738 - val_loss: 0.1046 - val_accuracy: 0.9628\n",
            "Epoch 71/100\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.1072 - accuracy: 0.9738 - val_loss: 0.1039 - val_accuracy: 0.9628\n",
            "Epoch 72/100\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.1065 - accuracy: 0.9738 - val_loss: 0.1032 - val_accuracy: 0.9628\n",
            "Epoch 73/100\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1058 - accuracy: 0.9738 - val_loss: 0.1025 - val_accuracy: 0.9628\n",
            "Epoch 74/100\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1051 - accuracy: 0.9738 - val_loss: 0.1018 - val_accuracy: 0.9628\n",
            "Epoch 75/100\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1044 - accuracy: 0.9738 - val_loss: 0.1012 - val_accuracy: 0.9628\n",
            "Epoch 76/100\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1037 - accuracy: 0.9738 - val_loss: 0.1006 - val_accuracy: 0.9628\n",
            "Epoch 77/100\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1031 - accuracy: 0.9738 - val_loss: 0.1000 - val_accuracy: 0.9681\n",
            "Epoch 78/100\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.1025 - accuracy: 0.9738 - val_loss: 0.0994 - val_accuracy: 0.9681\n",
            "Epoch 79/100\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1019 - accuracy: 0.9738 - val_loss: 0.0987 - val_accuracy: 0.9681\n",
            "Epoch 80/100\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.1013 - accuracy: 0.9738 - val_loss: 0.0981 - val_accuracy: 0.9681\n",
            "Epoch 81/100\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1007 - accuracy: 0.9738 - val_loss: 0.0976 - val_accuracy: 0.9681\n",
            "Epoch 82/100\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.1001 - accuracy: 0.9738 - val_loss: 0.0971 - val_accuracy: 0.9681\n",
            "Epoch 83/100\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0995 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9681\n",
            "Epoch 84/100\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0990 - accuracy: 0.9738 - val_loss: 0.0960 - val_accuracy: 0.9681\n",
            "Epoch 85/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0985 - accuracy: 0.9738 - val_loss: 0.0955 - val_accuracy: 0.9681\n",
            "Epoch 86/100\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0979 - accuracy: 0.9738 - val_loss: 0.0950 - val_accuracy: 0.9681\n",
            "Epoch 87/100\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0975 - accuracy: 0.9738 - val_loss: 0.0946 - val_accuracy: 0.9681\n",
            "Epoch 88/100\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0969 - accuracy: 0.9738 - val_loss: 0.0940 - val_accuracy: 0.9681\n",
            "Epoch 89/100\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0965 - accuracy: 0.9738 - val_loss: 0.0935 - val_accuracy: 0.9681\n",
            "Epoch 90/100\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0959 - accuracy: 0.9738 - val_loss: 0.0931 - val_accuracy: 0.9681\n",
            "Epoch 91/100\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0955 - accuracy: 0.9738 - val_loss: 0.0926 - val_accuracy: 0.9681\n",
            "Epoch 92/100\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0950 - accuracy: 0.9738 - val_loss: 0.0921 - val_accuracy: 0.9681\n",
            "Epoch 93/100\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0946 - accuracy: 0.9738 - val_loss: 0.0917 - val_accuracy: 0.9681\n",
            "Epoch 94/100\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0942 - accuracy: 0.9738 - val_loss: 0.0912 - val_accuracy: 0.9681\n",
            "Epoch 95/100\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0937 - accuracy: 0.9738 - val_loss: 0.0908 - val_accuracy: 0.9681\n",
            "Epoch 96/100\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0933 - accuracy: 0.9738 - val_loss: 0.0905 - val_accuracy: 0.9681\n",
            "Epoch 97/100\n",
            "381/381 [==============================] - 0s 166us/sample - loss: 0.0929 - accuracy: 0.9764 - val_loss: 0.0900 - val_accuracy: 0.9681\n",
            "Epoch 98/100\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0925 - accuracy: 0.9764 - val_loss: 0.0895 - val_accuracy: 0.9681\n",
            "Epoch 99/100\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.0921 - accuracy: 0.9764 - val_loss: 0.0892 - val_accuracy: 0.9681\n",
            "Epoch 100/100\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0917 - accuracy: 0.9764 - val_loss: 0.0889 - val_accuracy: 0.9681\n",
            "381/381 [==============================] - 0s 65us/sample - loss: 0.0914 - accuracy: 0.9764\n",
            "Train score: [0.09140375604623259, 0.97637796]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAUhuSFZj9hv",
        "colab_type": "code",
        "outputId": "76419e0c-4676-4500-8ed6-7d09e65b03ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot what's returned by model.fit()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2dec6970b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf7q_HJlnKvb",
        "colab_type": "code",
        "outputId": "c766a72a-c8a5-4a4f-8f72-9958ab69a23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot the accuracy too\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f2dec12fa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvACYLmXnNXR",
        "colab_type": "code",
        "outputId": "b8a23919-6e0f-416d-ee96-b473b91eba1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Make predictions\n",
        "P = model.predict(X_test)\n",
        "print(P) # they are outputs of the sigmoid, interpreted as probabilities p(y = 1 | x)\n",
        "# Round to get the actual predictions\n",
        "# Note: has to be flattened since the targets are size (N,) while the predictions are size (N,1)\n",
        "import numpy as np\n",
        "P = np.round(P).flatten()\n",
        "print(P)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.2806179e-04]\n",
            " [9.9102449e-01]\n",
            " [9.1672784e-01]\n",
            " [3.4811813e-02]\n",
            " [8.6599487e-01]\n",
            " [7.5282723e-01]\n",
            " [8.1852245e-01]\n",
            " [9.9806815e-01]\n",
            " [9.9374855e-01]\n",
            " [1.7743609e-05]\n",
            " [2.4500322e-03]\n",
            " [3.3574356e-08]\n",
            " [1.2640113e-05]\n",
            " [9.9198192e-01]\n",
            " [1.4263123e-03]\n",
            " [9.1075182e-01]\n",
            " [8.7221354e-01]\n",
            " [9.6464789e-01]\n",
            " [6.8532139e-01]\n",
            " [4.5942251e-02]\n",
            " [5.1496018e-02]\n",
            " [5.8056408e-01]\n",
            " [3.5564930e-03]\n",
            " [9.9863917e-01]\n",
            " [3.6095020e-01]\n",
            " [6.3372403e-03]\n",
            " [4.1099051e-05]\n",
            " [2.4731928e-01]\n",
            " [9.9277836e-01]\n",
            " [9.7312647e-01]\n",
            " [4.0599811e-01]\n",
            " [9.9470490e-01]\n",
            " [2.9813364e-06]\n",
            " [6.3080561e-06]\n",
            " [9.8000127e-01]\n",
            " [2.5669765e-02]\n",
            " [6.1749822e-01]\n",
            " [9.7272867e-01]\n",
            " [2.2711237e-01]\n",
            " [9.9099416e-01]\n",
            " [9.9408913e-01]\n",
            " [9.9971777e-01]\n",
            " [4.1608964e-03]\n",
            " [1.0527220e-03]\n",
            " [5.4487400e-03]\n",
            " [7.9047614e-01]\n",
            " [1.8918942e-01]\n",
            " [9.9387097e-01]\n",
            " [9.7817802e-01]\n",
            " [9.5590049e-01]\n",
            " [9.7269475e-01]\n",
            " [9.7800839e-01]\n",
            " [8.3905703e-01]\n",
            " [9.9603015e-01]\n",
            " [1.3923978e-09]\n",
            " [2.6551622e-03]\n",
            " [9.8578358e-01]\n",
            " [9.9401456e-01]\n",
            " [5.4643694e-02]\n",
            " [4.3332539e-02]\n",
            " [9.8405266e-01]\n",
            " [9.8753113e-01]\n",
            " [5.1728803e-01]\n",
            " [9.9732912e-01]\n",
            " [2.0982464e-08]\n",
            " [9.7231174e-01]\n",
            " [3.7794596e-06]\n",
            " [9.8688459e-01]\n",
            " [9.9222589e-01]\n",
            " [9.9794441e-01]\n",
            " [2.6455620e-01]\n",
            " [9.9405128e-01]\n",
            " [1.3089929e-02]\n",
            " [3.4343946e-01]\n",
            " [9.5738220e-01]\n",
            " [9.1063982e-01]\n",
            " [3.6046647e-03]\n",
            " [4.1665721e-01]\n",
            " [9.9965107e-01]\n",
            " [9.9633563e-01]\n",
            " [9.8569703e-01]\n",
            " [3.3800546e-03]\n",
            " [3.4931210e-01]\n",
            " [9.8699063e-01]\n",
            " [9.0399250e-02]\n",
            " [9.9850428e-01]\n",
            " [2.7837745e-05]\n",
            " [9.9905854e-01]\n",
            " [2.8417071e-03]\n",
            " [2.6286356e-02]\n",
            " [6.8415666e-01]\n",
            " [9.0822887e-01]\n",
            " [9.5345104e-01]\n",
            " [1.9786915e-02]\n",
            " [9.5397180e-01]\n",
            " [7.5559515e-01]\n",
            " [9.7446287e-01]\n",
            " [9.9131763e-01]\n",
            " [9.9858022e-01]\n",
            " [3.7676969e-04]\n",
            " [9.6482388e-04]\n",
            " [9.5102647e-03]\n",
            " [8.6026639e-01]\n",
            " [6.6832020e-03]\n",
            " [9.0599769e-01]\n",
            " [9.8836398e-01]\n",
            " [9.5397866e-01]\n",
            " [1.4387479e-01]\n",
            " [8.9952471e-03]\n",
            " [5.2256940e-04]\n",
            " [4.2595927e-04]\n",
            " [9.9482590e-01]\n",
            " [2.8859039e-03]\n",
            " [9.9987888e-01]\n",
            " [1.7792110e-03]\n",
            " [9.9928266e-01]\n",
            " [9.8675019e-01]\n",
            " [9.7915274e-01]\n",
            " [4.7832972e-01]\n",
            " [9.2432714e-01]\n",
            " [9.8615396e-01]\n",
            " [9.1254389e-01]\n",
            " [9.8702687e-01]\n",
            " [9.9820638e-01]\n",
            " [9.9599177e-01]\n",
            " [9.9488246e-01]\n",
            " [9.7863072e-01]\n",
            " [2.0674616e-02]\n",
            " [9.7922301e-01]\n",
            " [9.6789372e-01]\n",
            " [9.9409217e-01]\n",
            " [6.3784764e-06]\n",
            " [2.4305107e-01]\n",
            " [9.9698716e-01]\n",
            " [7.8420383e-01]\n",
            " [9.9287558e-01]\n",
            " [9.9936455e-01]\n",
            " [9.8742050e-01]\n",
            " [9.9855918e-01]\n",
            " [7.9883721e-06]\n",
            " [9.9131763e-01]\n",
            " [9.5869827e-01]\n",
            " [8.0940539e-01]\n",
            " [9.5771027e-01]\n",
            " [9.9914289e-01]\n",
            " [6.1492026e-01]\n",
            " [2.4031668e-05]\n",
            " [6.7321646e-01]\n",
            " [9.8989701e-01]\n",
            " [3.8427379e-02]\n",
            " [9.9170965e-01]\n",
            " [9.8218590e-01]\n",
            " [9.6459174e-01]\n",
            " [9.9740160e-01]\n",
            " [7.3387074e-01]\n",
            " [9.8599201e-01]\n",
            " [9.9801433e-01]\n",
            " [9.9108082e-01]\n",
            " [6.7167491e-01]\n",
            " [9.9816340e-01]\n",
            " [7.5517136e-01]\n",
            " [1.0281456e-01]\n",
            " [9.2462260e-01]\n",
            " [9.3848652e-01]\n",
            " [9.9175078e-01]\n",
            " [9.9531859e-01]\n",
            " [9.7824889e-04]\n",
            " [7.9198435e-05]\n",
            " [9.9579018e-01]\n",
            " [9.7995126e-01]\n",
            " [9.6770477e-01]\n",
            " [3.0304776e-05]\n",
            " [9.6788466e-01]\n",
            " [9.9859029e-01]\n",
            " [9.9901283e-01]\n",
            " [9.4888252e-01]\n",
            " [2.2090501e-04]\n",
            " [3.6125594e-01]\n",
            " [1.6806088e-02]\n",
            " [9.4219893e-01]\n",
            " [9.9633336e-01]\n",
            " [5.7517052e-05]\n",
            " [9.1477424e-01]\n",
            " [9.8702061e-01]\n",
            " [6.5601914e-04]\n",
            " [9.9820018e-01]\n",
            " [9.9825221e-01]\n",
            " [9.1565514e-01]]\n",
            "[0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5IbMLX4nUJQ",
        "colab_type": "code",
        "outputId": "e139b543-7c05-429c-c85e-7ea760345d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Calculate the accuracy, compare it to evaluate() output\n",
        "print(\"Manually calculated accuracy:\", np.mean(P == y_test))\n",
        "print(\"Evaluate output:\", model.evaluate(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manually calculated accuracy: 0.9680851063829787\n",
            "188/188 [==============================] - 0s 84us/sample - loss: 0.0889 - accuracy: 0.9681\n",
            "Evaluate output: [0.0888901948136218, 0.9680851]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwFSZTJMnWyI",
        "colab_type": "code",
        "outputId": "d287e624-7a00-4afc-e5cf-94343546891e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Let's now save our model to a file\n",
        "model.save('linearclassifier.h5')\n",
        "# Check that the model file exists\n",
        "!ls -lh "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 24K\n",
            "-rw-r--r-- 1 root root  19K Jan 20 15:51 linearclassifier.h5\n",
            "drwxr-xr-x 1 root root 4.0K Jan 13 16:38 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffmXXOEnnapw",
        "colab_type": "code",
        "outputId": "46107bb6-709c-46a0-b095-864c526a8ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Let's load the model and confirm that it still works\n",
        "# Note: there is a bug in Keras where load/save only works if you DON'T use the Input() layer explicitly\n",
        "# So, make sure you define the model with ONLY Dense(1, input_shape=(D,))\n",
        "# At least, until the bug is fixed\n",
        "# https://github.com/keras-team/keras/issues/10417\n",
        "model = tf.keras.models.load_model('linearclassifier.h5')\n",
        "print(model.layers)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.core.Dense object at 0x7f2dec05f160>]\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.0889 - accuracy: 0.9681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0888901948136218, 0.9680851]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3QqlrYDndSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file - requires Chrome (at this point)\n",
        "from google.colab import files\n",
        "files.download('linearclassifier.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}